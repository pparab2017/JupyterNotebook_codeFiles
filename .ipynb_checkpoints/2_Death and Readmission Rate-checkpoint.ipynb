{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Death and Readmission Rate (2012-2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output \n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "import plotly\n",
    "# Set Plotly credetials\n",
    "\n",
    "plotly.tools.set_credentials_file(username='pparab', api_key='jgQSn7NrsQAUnpx26Aks')\n",
    "import plotly.plotly as py\n",
    "import plotly.tools as plotly_tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    " #Sign in the plotly API\n",
    "py.sign_in(\"pparab\", \"jgQSn7NrsQAUnpx26Aks\")\n",
    "\n",
    "\n",
    "\n",
    "ReqData = \"/Users/pushparajparab/Desktop/Hospital_Revised_Flatfiles/Readmissions_and_Deaths_Hospital.csv\"\n",
    "df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(ReqData)\n",
    "df.registerTempTable('Data')\n",
    "\n",
    "_selectedCat = [\"NA\"]\n",
    "_selectedMeasure = [\"NA\"]\n",
    "_d = []\n",
    "_s = []\n",
    "_text = []\n",
    "_name = []\n",
    "_d2 = []\n",
    "_s2 = []\n",
    "_text2 = []\n",
    "_name2 = []\n",
    "_d3 = []\n",
    "_s3 = []\n",
    "_text3 = []\n",
    "_name3 = []\n",
    "\n",
    "\n",
    "def runQuery():\n",
    "    del _d[:]\n",
    "    del _s[:]\n",
    "    del _text[:]\n",
    "    del _name[:]\n",
    "    del _d2[:]\n",
    "    del _s2[:]\n",
    "    del _text2[:]\n",
    "    del _name2[:]\n",
    "    del _d3[:]\n",
    "    del _s3[:]\n",
    "    del _text3[:]\n",
    "    del _name3[:]\n",
    "    data1= \"SELECT Denominator,Score,Compared_to_National,Hospital_Name from Data \"\n",
    "    data1+= \" where Measure_Name = '\"+ _selectedMeasure[0] + \"' \"\n",
    "    data1+= \" AND Compared_to_National = 'No Different than the National Rate' \"\n",
    "    if _selState[0] != \"All\":\n",
    "       data1 = data1 + \" AND State = '\" + _selState[0] +\"'\" \n",
    "    categoryName = spark.sql(data1)\n",
    "    _dataList = categoryName.collect()\n",
    "\n",
    "    for i in range(len(_dataList)):\n",
    "        _d.append(_dataList[i][0])\n",
    "        _s.append(_dataList[i][1])\n",
    "        _text.append(_dataList[i][2] + \", \" + _dataList[i][3])\n",
    "        _name.append(_dataList[i][3])  \n",
    "    data2= \"SELECT Denominator,Score,Compared_to_National,Hospital_Name from Data \"\n",
    "    data2+= \" where Measure_Name = '\"+ _selectedMeasure[0] + \"' \"\n",
    "    data2+= \" AND Compared_to_National = 'Worse than the National Rate' \"\n",
    "    if _selState[0] != \"All\":\n",
    "       data2 = data2 + \" AND State = '\" + _selState[0] +\"'\" \n",
    "    categoryName2 = spark.sql(data2)\n",
    "    _dataList2 = categoryName2.collect()\n",
    "\n",
    "#         categoryName2.show()\n",
    "    for i in range(len(_dataList2)):\n",
    "        _d2.append(_dataList2[i][0])\n",
    "        _s2.append(_dataList2[i][1])\n",
    "        _text2.append(_dataList2[i][2] + \", \" + _dataList2[i][3])\n",
    "        _name2.append(_dataList2[i][3])\n",
    "\n",
    "    data3= \"SELECT Denominator,Score,Compared_to_National,Hospital_Name from Data \"\n",
    "    data3+= \" where Measure_Name = '\"+ _selectedMeasure[0] + \"' \"\n",
    "    data3+= \" AND Compared_to_National = 'Better than the National Rate' \"\n",
    "    if _selState[0] != \"All\":\n",
    "       data3 = data3 + \" AND State = '\" + _selState[0] +\"'\" \n",
    "    categoryName3 = spark.sql(data3)\n",
    "    _dataList3 = categoryName3.collect()\n",
    "\n",
    "#         categoryName2.show()\n",
    "    for i in range(len(_dataList3)):\n",
    "        _d3.append(_dataList3[i][0])\n",
    "        _s3.append(_dataList3[i][1])\n",
    "        _text3.append(_dataList3[i][2] + \", \" + _dataList3[i][3])\n",
    "        _name3.append(_dataList3[i][3])   \n",
    "\n",
    "\n",
    "def on_change2(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        clear_output()\n",
    "        _selectedMeasure[0] = change['new']\n",
    "        runQuery()\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        clear_output()\n",
    "        _selectedCat[0] = (change['new'])  \n",
    "        _query_O = \"SELECT distinct Measure_Name from Data\" \n",
    "        if (change['new']) == \"Death Rate\" :\n",
    "            _query_O = _query_O +  \" WHERE Measure_ID LIKE '%MORT%'\"\n",
    "        else :\n",
    "            _query_O = _query_O +  \" WHERE Measure_ID LIKE '%READM%'\"\n",
    "            \n",
    "        TypeName = spark.sql(_query_O)  \n",
    "        _types = []\n",
    "        type_nameList = TypeName.collect();\n",
    "        for i in range(len(type_nameList)):\n",
    "            _types.append(type_nameList[i][0])\n",
    "        select1.options = _types\n",
    "           \n",
    " \n",
    "select = widgets.Dropdown(\n",
    "    options=[\"NA\",\"Death Rate\",\"Readmission Rate\"],\n",
    "    description='Category:',\n",
    "    disabled=False\n",
    ")\n",
    "display(select)\n",
    "\n",
    "\n",
    "\n",
    "_selState = [\"All\"]\n",
    "def on_change_State(change):\n",
    "     if change['type'] == 'change' and change['name'] == 'value':\n",
    "        clear_output()\n",
    "        _selState[0] = change['new']\n",
    "        runQuery()\n",
    "\n",
    "states= \"SELECT distinct state from Data Order by State \"\n",
    "state_Q = spark.sql(states)\n",
    "stateList = state_Q.collect()\n",
    "_states = []    \n",
    "_states.append(\"All\")\n",
    "#         categoryName2.show()\n",
    "for i in range(len(stateList)):\n",
    "    _states.append(stateList[i][0])\n",
    "\n",
    "statesDD = widgets.Dropdown(\n",
    "    options=_states,\n",
    "    description='State:',\n",
    "    disabled=False\n",
    ")\n",
    "display(statesDD)\n",
    "\n",
    "statesDD.observe(on_change_State)\n",
    "\n",
    "\n",
    "select1 = widgets.Dropdown(\n",
    "        \n",
    "        description='Measure Name:',\n",
    "        disabled=False\n",
    "        )\n",
    "display(select1)\n",
    "select1.observe(on_change2) \n",
    "\n",
    "select.observe(on_change)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~pparab/32.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace = go.Scatter(\n",
    "            x = _s,\n",
    "            y = _d,\n",
    "            mode = 'markers',\n",
    "            name = \"Same\",\n",
    "            text = _text \n",
    "        )\n",
    "trace2 = go.Scatter(\n",
    "            x = _s2,\n",
    "            y = _d2,\n",
    "            name = \"Worse\",\n",
    "            mode = 'markers',\n",
    "            text = _text2 \n",
    "        )\n",
    "\n",
    "trace3 = go.Scatter(\n",
    "            x = _s3,\n",
    "            y = _d3,\n",
    "             name = \"Better\",\n",
    "            mode = 'markers',\n",
    "            text = _text3 \n",
    "        )\n",
    "data = [trace,trace2,trace3]\n",
    "# Plot and embed in ipython notebook!\n",
    "py.iplot(data, filename='basic-scatter_Death_Read')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {
    "2f2f432a91234002af4ee61cade49e69": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "6a98f01cabba4f2490d36efe1195e9f2": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "6febd334895d4a64a11c8d04466e47a7": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    },
    "db6ae9131d3347e48e1485ba46e08409": {
     "views": [
      {
       "cell_index": 1
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
